{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "\n",
    "f_width = 1024//4\n",
    "f_height = 576//4\n",
    "f_channels = 1\n",
    "f_batch_size = 10\n",
    "\n",
    "command = [ \"ffmpeg\",\n",
    "            '-i', '/home/veon/Downloads/Birkebeinertraseen.1024x576p50.3Mb.h264.NRK/Birkebeinertraseen.1024x576p50.3Mb.h264.NRK.mp4',\n",
    "            '-vf', 'scale='+str(f_width)+':'+str(f_height),\n",
    "            '-f', 'image2pipe',\n",
    "            '-pix_fmt', 'gray',\n",
    "            '-vcodec', 'rawvideo', '-']\n",
    "pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8)\n",
    "\n",
    "def readFrames(num) :\n",
    "    raw_image = pipe.stdout.read(f_batch_size*f_height*f_width*f_channels)\n",
    "   \n",
    "    # transform the byte read into a numpy array\n",
    "    image =  np.fromstring(raw_image, dtype='uint8').astype('float32') / 255\n",
    "    return image.reshape ((f_batch_size, f_height, f_width, f_channels))\n",
    "\n",
    "\n",
    "patch_size = (7,7)\n",
    "rng = np.random.RandomState(0)\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "def getAllPathes(img=None):\n",
    "    if img is None:\n",
    "        img = readFrames(1)[0]\n",
    "    \n",
    "    r = skimage.util.view_as_windows(img.squeeze(), patch_size, step=patch_size)\n",
    "    return r.reshape(r.shape[0], r.shape[1],-1)\n",
    "\n",
    "\n",
    "def getPatches(max_patches):\n",
    "    for img in readFrames(1):\n",
    "        data = extract_patches_2d(img, patch_size, max_patches=max_patches,\n",
    "                                  random_state=rng)\n",
    "\n",
    "        data = np.reshape(data, (max_patches, -1))\n",
    "        return data\n",
    "    \n",
    "    \n",
    "def display_img(patches):\n",
    "    plt.figure()\n",
    "    shape = np.shape(patches)\n",
    "    PATCH_SIDE = patch_size[0]\n",
    "    im = np.empty([shape[-3]*PATCH_SIDE,shape[-2]*PATCH_SIDE])#, axis=3)\n",
    "    for yy in range(shape[-3]):\n",
    "        for xx in range(shape[-2]):\n",
    "            z = np.reshape(patches[yy][xx], [PATCH_SIDE,PATCH_SIDE])\n",
    "            im[yy*PATCH_SIDE:(yy+1)*PATCH_SIDE,xx*PATCH_SIDE:(xx+1)*PATCH_SIDE] = z\n",
    "    \n",
    "    plt.matshow(im,cmap=plt.cm.gray)\n",
    "    #display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def _patchGenerator(frames, max_patches):\n",
    "    while True:\n",
    "        for img in readFrames(frames):\n",
    "            data = extract_patches_2d(img, patch_size, max_patches=max_patches,\n",
    "                                      random_state=rng)\n",
    "\n",
    "            data = np.reshape(data, (max_patches, -1))\n",
    "            yield (data, data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "\n",
    "from keras.callbacks import History, ModelCheckpoint, LambdaCallback\n",
    "from IPython import display\n",
    "\n",
    "def plot_progress(epoch,logs):\n",
    "    plt.figure()\n",
    "    plt.plot(range(epoch+1),history.history['loss'],'b',label='trainin loss')\n",
    "    #plt.plot(range(epoch+1),history.history['val_loss'],'r',label='validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('training error')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.close()\n",
    "    \n",
    "history = History()\n",
    "plot_progress_cb = LambdaCallback(on_epoch_end=plot_progress)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viz_square(data, normalize=True, cmap=plt.cm.gray, padsize=1, padval=0):\n",
    "    \"\"\"\n",
    "    takes a np.ndarray of shape (n, height, width) or (n, height, width, channels)\n",
    "    visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
    "    However, this only draws first input channel\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (20,20))\n",
    "    # normalize to 0-1 range\n",
    "    if normalize:\n",
    "        data -= data.min()\n",
    "        data /= data.max()\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0]))) # force square \n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    plt.imshow(data,cmap=cmap)\n",
    "    \n",
    "def display_weights(epoch = None, logs = None):\n",
    "    w = np.rollaxis(encoder.get_weights()[0], 1)\n",
    "    im = np.reshape(w, [encoding_layer_size, patch_size[0], patch_size[1]])\n",
    "    \n",
    "    viz_square(im)\n",
    "    display.display(plt.gcf())\n",
    "    plt.close()\n",
    "    \n",
    "display_weights_cb = LambdaCallback(on_epoch_end=display_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "with K.tf.device('/gpu:0'):\n",
    "    K.set_session(K.tf.Session(config=K.tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)))\n",
    "    \n",
    "\n",
    "encoding_layer_size = 36 \n",
    "samples_per_epoch=5000\n",
    "nb_epoch=200\n",
    "\n",
    "inp_size = patch_size[0]*patch_size[1]\n",
    "\n",
    "input_img = Input(shape=(inp_size, )) #batch_shape=(batch_size, inp_size)\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_layer_size, activation='sigmoid'\n",
    "               #, activity_regularizer=regularizers.activity_l1(2*10e-6)\n",
    "               )(input_img)\n",
    "decoded = Dense(inp_size, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "encoded_input = Input(shape=(encoding_layer_size,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "autoencoder.fit_generator(_patchGenerator(f_batch_size, batch_size), samples_per_epoch, nb_epoch,\n",
    "                          #shuffle=True,\n",
    "                         callbacks=[history, plot_progress_cb],  # display_weights_cb\n",
    "                         verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = getAllPathes()\n",
    "x_test = f.reshape(-1, f.shape[-1])\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "display_img(x_test.reshape(f.shape))\n",
    "display_img(decoded_imgs.reshape(f.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 20 # how many pathes we will display\n",
    "x_test = getPatches(n)\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "plt.figure(figsize=(40, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(7, 7))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(7, 7))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "display.display(plt.gcf())\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
